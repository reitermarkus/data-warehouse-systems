\documentclass[../paper.tex]{subfiles}

\begin{document}

For small and medium businesses, probably the most important aspect when
choosing a data warehouse system is cost, both for the initial development and
for the ongoing maintenance of such a system.

Nowadays, Software as a Service (SaaS) can provide many advantages over
traditional services. The pay-as-you-go model is very friendly towards small
businesses which could not otherwise easily justify the upfront cost for
servers and related costs for hosting a data warehouse.

This means that, in many cases, SaaS is the most cost-effective and also the
simplest solution for small businesses to opt for. When comparing them to
traditional services, SaaS products virtually don't need any setup time and
can be deployed instantly.

In the case of data warehouse systems, SaaS is also commonly referred to as
Data Warehouse as a Service (DWaaS).

Given the advantages above, we focus in this section on some concrete DWaaS
products and review what they have in common, how they differ and whether they
are in fact suitable for small businesses.

\subsection{Segment (by Twilio)}

After first logging into Segment, the user can choose the team they are working on (Engineering, Marketing, Founder/Executive, Product, Analytics) and select the first data source, e.g. a website, programming language or HTTP API. Next, data destinations have to be selected, e.g. Google Analytics, Intercom, etc. Finally, the user gets to the dashboard, which provides an overview of all data sources and destinations and a way to add new ones.

In total, Segment supports 98 different data sources and 650 data destinations at the time of writing. Additionally, creating custom data sources and destinations by building JavaScript function that access the corresponding API. Also, by supporting programming languages as data source and webhooks as data destinations, virtually any software can be integrated.

Segment does not offer any Analytics capability on its own but is meant to simplify data collection and distribution by managing all data sources and destinations in a single place, therefore reducing complexity and increasing flexibility. For example, website analytics can be switched from Google Analytics~\cite{google_analytics} to GoSquared~\cite{gosquared} without changing the website itself.

\subsection{Panoply}

\textit{Panoply} is a data warehouse solution build on \textit{AWS Redshift} and offers four plans: \textit{LITE}, \textit{STARTER}, \textit{PRO} and \textit{BUSINESS}. The last of them is specifically aimed at SMBs, according to their own website. There is a free version available for testing which has the functionality if the \textit{LITE} plan for a period of 14 days. After logging in for the first time, the website prompts a user to create a data warehouse, that is required to have a unique name. Next, a user is prompted with the possibility of adding a data source, which can also be skipped. Afterwards, the user has full access to the instance.

\textit{Panoply} offers the integration of 122 data sources that have been integrated by the Panoply team. Additionally, there are 131 data sources, which are developed by partners, that can be added. In total, 253 different data source are supported. To analyse the collected data, \textit{Panoply} offers the integration of 43 visualisation tools, of which 42 are \textit{BI} tools.

\textit{Panoply} is a full solution to sync, store and access a companies data, while also providing analytic features. Additionally to the supported visualisation tools, data can be structured and viewed in a traditional tabular form.

The different pricing tiers are differentiated by three main parts: amount of data sources, storage space and support. The suggested SMB solution, called the \textit{BUSINESS} plan, includes 10 distinct data sources, 100 GB of storage and support with a reaction time of less than an hour. It also includes \textit{Data Governance} features, yet the storage itself is based in the \textit{USA}, without any other option. All plans offer an unlimited amount of users. More storage and data sources is possible for the \textit{Enterprise} plan, which is adapted to a companies needs. This adds the possibility of storing the data in one of 19 different countries.

\subsection{Snowflake}
\textit{Snowflake} is a data warehouse solution build on top of Amazon Web Services, Microsoft  Azure or Google Cloud Platform. It aims to fulfill the majority of data analytics needs, such as data storage, data processing, data integration and it provides analytic solutions. Snowflake offers multiple editions of cloud data platform service (1) Standard Edition (2) Enterprise Edition (3) Business Critical Edition (4) Virtual Private Snowflake (VPS). 
The standard  edition offers unlimited access to all standard features in the platform. Additionally the enterprise edition contains features designed especially for the needs of large-scale oganizations and enterprises.
Furthermore, the business critical edition and the virtual private snowflake edition are for organizations who are dealing with extremely sensitive data. The editions contain strict requirements and provide higher levels of data protection. Snowflake also offers a 30-day trial with \$400 worth of free usage. Before the login the user has to choose which cloud platform he wants to use.
\\ \\
The \textit{Snowflake} platform uses a unique architecture consisting of three layers: (1) Database Storage (2) Query Processing and (3) Cloud Services. In the database storage layer data is loaded into the platform. After the loading process the data will be optimized, compressed and stored in an cloud storage. 
\textit{Snowflake} manages all aspects on how the data is stored: the organization, structure, metadata, statistics and many more. The data objects are then accessible through SQL query operations in the platform.
In the query processing or virtual warehouse layer the query execution is performed. This is done by using "virtual warehouses". Each virtual warehouse is an independent compute cluster which means that each virtual warehouse has no impact on the performance of other virtual warehouses. The warehouse comes with different sizes ranging form XS (extra small) to XXXL, depending on the organizations needs. Each size comes with different credits wich is important for the pricing. The cloud service layer is responsible for the coordination of activities across the platform, such as authentication, infrastructure management, query parsing and optimization and metadata management. 
\\ \\
The pricing of theses layer depends on their actual usage. Snowflake offers two different pricing options. The first one is "On Demand". Customers are charged a fixed rate for the services that are consumed and are billed every month. The second one is "Pre-Purchased Capacity". A company can pre-purchase capacity which is the consumed on a monthly basis. Furthermore \textit{Snowflake} offers an pricing overview for each cloud platform and region on their website. As an example, a standard-level data warehouse running on amazon web services in the european region will cost \$2.70 per credit. And in addition one TB of on demand storage will cost \$45 per month. \\ \\
To sum up, snowflakes data warehouse platform offers all the tools necessary to store, retrieve, analyze and process data. The platform provides good solutions for small business as well as for big organizations. 
\subsection{Tableau}

\textit{Tableau} is a visualisation software which mainly focuses on data visualisation and data reporting. This tool is found by \textit{Tableau Software  Inc.} and is now owned by the Cloud Computing Solutions company \textit{Salesforce.com}. \textit{Tableau} uses a machine learning based analysis engine which helps modelling  automated structured data tables and displays statistical findings. Analytics or Business Intelligence is a cycle with different steps. 

Transactions need to be stored securely before data analysts periodically analyse the data. Afterwards these insights are shared across the company where then senior colleagues make decisions before the outcomes get monitored from managers who change product offers. \textit{Tableau} has six key products which aim at improving the work-flow for every of the six previously mentioned cycle step by offering a simple to use, connected platform. 

For storing data tableau does not use a dedicated database but uses a special file type called \textit{.tde} or more recent \textit{.hyper}. Since data is not stored correctly all time due to a missing category or a wrong scanned item. To handle these mistakes it needs to be fixed manually every time or in bulk periodically. The Tableau tool \textit{Tableau Prep Builder} allows users to clean, shape and prepare data by making it ease deleting, moving or even merging fields from different data sources. After cleaning data, \textit{Tableau Desktop} \& \textit{Tableau Public} connect to the clean data and are able to analyse it. \textit{Tableau Desktop} allows users to connect to basically any data source they want like Excel-Spreadsheet, billion row databases and even to a web-API. In total both \textit{Desktop} \& \textit{Public} support more than 80 different data sources including hundreds of web data connectors used to grab data from e.g. HTML, JSON \& XML.  Analysis can be done by simply drag and drop and analysts can also ask questions inside the tool and get the corresponding answer displayed as data. \textit{Tableau Public} on the other hand can do the same as the desktop version but users can only share dashboards and insights with others also using the public version, basically a community , non profit, free edition of \textit{Tableau Desktop}. After preparing and connecting to data in order to build reports, analysis can't be done by a single person. To share these across the business, it needs a tool which is safe and secure, to prevent access from others. Also collaboration between analysts and being able to withstand numerous requests should be key factors of such a tool. \textit{Tableau Server} \& \textit{Tableau Online} offer all these aspects and on top of it, in case of the first one, runs locally inside the business and the second one runs online, powered by the \textit{Tableau Cloud}. One major downside of running the server in \textit{Tableau's} cloud is the storage limitation to 100GB per site. Employees on the go can access data within the \textit{Tableau Mobile} apps. Compared to other tools \textit{Tableau} offers data visualisation out-of-the-box by dragging and dropping columns and rows into desired fields before choosing the desired visualisation type like histogram, box-and-whisker and any further combination between these 30 types are possible.

Except for the \textit{Tableau Public} which is the only free version build to share data inside the Tableau-community, every other tool needs to be purchased. In this case \textit{Tableau} offers a package for individuals containing \textit{Desktop, Prep Builder \& Server} or \textit{Online} which costs \$70 per user per month. In case of teams and organisations packages are available from \textit{Viewer} to \textit{Explorer} and \textit{Creator} ranging from \$12 up to \$70 per user per month, where the first one is only basic functionality and the last one includes the full package. Taking all these different packages into account the best solution for SMEs would be the \textit{Tableau Creator} package and let the \textit{Server} run in the SME's datacenter in order to have more storage than 100GB. 

 
\end{document}
